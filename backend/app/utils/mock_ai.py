"""Mock AI generator for test runs and cases."""

from __future__ import annotations

import random
from datetime import datetime, timedelta
from typing import Sequence

from sqlalchemy.orm import Session

from .. import models

TEST_NAMES = [
    "Login form validation",
    "User authentication flow",
    "Shopping cart add item functionality",
    "Payment processing integration",
    "Navigation menu accessibility",
    "Form submission error handling",
    "API response time validation",
    "Mobile responsive layout check",
    "Search functionality accuracy",
    "User profile update flow",
]

PASS_INSIGHTS = [
    "✅ All form fields validated correctly according to specifications",
    "✅ Authentication flow completed successfully with proper token management",
    "✅ No accessibility violations detected, WCAG 2.1 AA compliant",
    "✅ Response time within acceptable threshold (< 200ms)",
]

FAIL_INSIGHTS = [
    "❌ AI detected: Submit button remained enabled during form validation failure",
    "❌ Potential issue: Missing error message for invalid email format",
    "❌ Accessibility concern: Form input missing aria-label attribute",
    "❌ Performance issue: API response exceeded 2000ms threshold",
    "❌ Navigation issue: Expected redirect to dashboard did not occur after login",
]

ERROR_MESSAGES = [
    "AssertionError: Expected element with selector '#submit-btn' to be disabled, but it was enabled",
    "TimeoutError: Element '.error-message' not found within 5000ms",
    "ValidationError: Expected status code 400, received 200",
]

STACK_TRACES = [
    "Traceback (most recent call last):\n  File \"/app/tests/test_checkout.py\", line 42, in test_checkout\n    assert disable_submit()\nAssertionError",
    "Traceback (most recent call last):\n  File \"/app/tests/test_auth.py\", line 88, in test_login_redirect\n    wait_for_selector('.error-message')\nTimeoutError: Element '.error-message' not found within 5000ms",
    "Traceback (most recent call last):\n  File \"/app/tests/test_api.py\", line 120, in test_payment\n    response.assert_status_code(400)\nAssertionError: Expected 400, received 200",
]


def start_run(db: Session, suite: models.TestSuite) -> models.TestRun:
    """Create an initial running test run record."""
    run = models.TestRun(suite_id=suite.id, status="running", started_at=datetime.utcnow())
    db.add(run)
    db.flush()
    return run


def complete_run_with_results(db: Session, run: models.TestRun) -> None:
    """Populate the given run with mock test case data."""
    num_cases = random.randint(15, 20)
    total_duration = 0
    passed = 0
    failed = 0

    for i in range(num_cases):
        status = "passed" if random.random() <= 0.8 else "failed"
        duration = random.randint(50, 800)
        total_duration += duration
        if status == "passed":
            passed += 1
        else:
            failed += 1

        case = models.TestCase(
            run_id=run.id,
            name=TEST_NAMES[i % len(TEST_NAMES)],
            description="Automated scenario generated by the AI engine",
            status=status,
            execution_time_ms=duration,
            ai_insight=random.choice(PASS_INSIGHTS if status == "passed" else FAIL_INSIGHTS),
            error_message=random.choice(ERROR_MESSAGES) if status == "failed" else None,
            stack_trace=random.choice(STACK_TRACES) if status == "failed" else None,
        )
        db.add(case)

    run.total_tests = num_cases
    run.passed_tests = passed
    run.failed_tests = failed
    run.duration_ms = total_duration
    run.completed_at = run.started_at + timedelta(milliseconds=total_duration)
    run.status = "passed" if failed == 0 else "failed"


def generate_historical_run(db: Session, suite: models.TestSuite, *, started_at: datetime) -> models.TestRun:
    """Create a completed run at a historical timestamp."""
    run = start_run(db, suite)
    run.started_at = started_at
    complete_run_with_results(db, run)
    return run

